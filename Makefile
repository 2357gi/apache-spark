PYFILE=æ­£ã—ãPYFILEã‚’è¨­å®šã—ã¦ãã ã•ã„

build_docker: Dockerfile
	@echo "\nğŸ“¦ build 2357gi/apache-spark"
	@docker build ./ -t 2357gi/apache-spark

build_compose:
	@echo "\nğŸ—  Pile up containers"
	@docker-compose up -d

run: docker-compose.yml
	@echo "\nâœ¨ apache-spark cluster setup is start!"
	@make build_docker
	@make build_compose
	@echo "\nğŸ¾ set up is finished! \n you wanna access âš¡spaek shell, hit it! \n$$ make  s-shell"
	@echo "or you wanna start ğŸ“” pyspark notebook, hit it! \n$$ make notebook"
	@echo "... if u wanna open ğŸš shell? do this. \n$$ make shell"
	@echo "\n or u have python file and wanna kickin spark with this, \n $$make kick-py PYFILE=<pythonfille>"
s-shell:
	@echo "\nâš¡ start spark-shell...."
	@docker-compose exec master /spark/bin/spark-shell --master spark://master:7077

notebook:
	@echo "\nğŸ“” start pyspark notebook...."
	@docker-compose exec master /spark/bin/pyspark --master spark://master:7077
	@docker-compose exec

shell:
	@echo "\nğŸš start master shell...."
	@docker-compose exec master /bin/bash


setup-jpnb:
	@echo "\n âš¡ pull jupyter/pyspark-notebook"
	@docker pull jupyter/pyspark-notebook

start-jpnb:
	@echo "\n âš¡ start docker notebook"
	@docker run -p 8888:8888 -v $(pwd)/work:/home/jovyan/work jupyter/pyspark-notebook start-notebook.sh

kick-py:
	@echo "\n ğŸ¯ lets kick spark with py-file!"
	@echo "\n target .py is ${PYFILE}"
	@docker-compose exec master /spark/bin/spark-submit --py-files ${PYFILE} ${PYFILE}


